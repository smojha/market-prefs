{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import csv\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "runs = [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n",
        "output_csv = 'forecast_output.csv'\n",
        "columns = [\"sesion\", \"round\", \"price\", \"prev_price\", \"part_label_ID\", \"pl_f0\", \"pl_f1\", \"pl_f2\", \"pl_f3\", \"pl_fcast_rnd_0\", \"pl_fcast_rnd_1\", \"pl_fcast_rnd_2\", \"pl_fcast_rnd_3\", \"pl_fcast_err_0\", \"pl_fcast_err_1\", \"pl_fcast_err_2\", \"pl_fcast_err_3\", \"model\"]\n",
        "metadata_file = \"runs.metadata\"\n",
        "mixed_bot_types_dict = {\n",
        "    1: \"gpt-3.5\",\n",
        "    2: \"gpt-3.5\",\n",
        "    3: \"gpt-3.5\",\n",
        "    4: \"gpt-3.5\",\n",
        "    5: \"gpt-4o\",\n",
        "    6: \"gpt-4o\",\n",
        "    7: \"gpt-4o\",\n",
        "    8: \"gpt-4o\",\n",
        "    9: \"gemini-1.5-pro\",\n",
        "    10: \"gemini-1.5-pro\",\n",
        "    11: \"gemini-1.5-pro\",\n",
        "    12: \"gemini-1.5-pro\",\n",
        "    13: \"grok-2\",\n",
        "    14: \"grok-2\",\n",
        "    15: \"grok-2\",\n",
        "    16: \"grok-2\",\n",
        "    17: \"mistral-large\",\n",
        "    18: \"mistral-large\",\n",
        "    19: \"mistral-large\",\n",
        "    20: \"mistral-large\",\n",
        "    21: \"claude-3.5-sonnet\",\n",
        "    22: \"claude-3.5-sonnet\",\n",
        "    23: \"claude-3.5-sonnet\",\n",
        "    24: \"claude-3.5-sonnet\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_metadata(filename):\n",
        "    # all metadata is in rows of this form: 2025-01-06 23:49:24.064839 | run-1 | gpt-3.5 | 20 subjects | Experiment 1/3 w/ 20 subjects and 3.5 using standard profit maximizing prompt + fixed auto timeout take 2 | hrei2bal\n",
        "    runs_metadata = {}\n",
        "    # add the runs with 'run-X' as key\n",
        "    with open(filename, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.split('|')\n",
        "            run_id = parts[1].strip()\n",
        "            # Make dict storing the rest of the parts\n",
        "            part_labels = [\"time\", \"run_id\", \"model\", \"num_subjects\", \"experiment_description\", \"session_id\"]\n",
        "            parts = {part_labels[i]: parts[i].strip() for i in range(0, len(part_labels))}\n",
        "            # Remove run_id from parts\n",
        "            del parts['run_id']\n",
        "            # Remove the run- prefix from run_id and cast to int\n",
        "            run_id = int(run_id.split('-')[1])\n",
        "            # Make num_subjects an int\n",
        "            parts['num_subjects'] = int(parts['num_subjects'].split(' ')[0])\n",
        "            runs_metadata[run_id] = parts\n",
        "    return runs_metadata\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_run(run_id, run_metadata, all_market_prices):\n",
        "    # Make dataframe for this run only using pd\n",
        "    run_data = pd.DataFrame(columns=columns)\n",
        "    run_folder = f\"run-{run_id}\"\n",
        "    num_subjects = run_metadata['num_subjects']\n",
        "    for subject in range(1, num_subjects+1):\n",
        "        # Concat session id and bot id to get the part_id\n",
        "        part_id = f\"{run_metadata['session_id']}bot{subject}\"\n",
        "        filename = f\"{run_folder}/bot-{subject}-history.json\"\n",
        "        # Load the json file\n",
        "        with open(filename, 'r') as f:\n",
        "            rounds = json.load(f)\n",
        "        # Drop the first 3 practice rounds\n",
        "        rounds = rounds[3:]\n",
        "        for i in range(len(rounds)):\n",
        "            # Extract the data\n",
        "            round = rounds[i]\n",
        "            round_num = int(round['round_num'])-3\n",
        "            forecast_dict = {}\n",
        "            for forecast in round['forecast']:\n",
        "                forecast_dict[forecast['field']] = forecast['input_forecast']\n",
        "            model = run_metadata['model']\n",
        "            if model == \"mixed\":\n",
        "                model = mixed_bot_types_dict[subject]\n",
        "            row = {\n",
        "                \"sesion\": run_metadata['session_id'],\n",
        "                \"round\": round_num,\n",
        "                \"price\": round['market_state']['market_price'],\n",
        "                \"prev_price\": rounds[i - 1]['market_state']['market_price'] if i > 0 else None,\n",
        "                \"part_label_ID\": part_id,\n",
        "                \"pl_f0\": forecast_dict['f0'] if 'f0' in forecast_dict else None,\n",
        "                \"pl_f1\": forecast_dict['f1'] if 'f1' in forecast_dict else None,\n",
        "                \"pl_f2\": forecast_dict['f2'] if 'f2' in forecast_dict else None,\n",
        "                \"pl_f3\": forecast_dict['f3'] if 'f3' in forecast_dict else None,\n",
        "                \"pl_fcast_rnd_0\": round_num if 'f0' in forecast_dict else None,\n",
        "                \"pl_fcast_rnd_1\": round_num + 2 if 'f1' in forecast_dict else None,\n",
        "                \"pl_fcast_rnd_2\": round_num + 5 if 'f2' in forecast_dict else None,\n",
        "                \"pl_fcast_rnd_3\": round_num + 10 if 'f3' in forecast_dict else None,\n",
        "                \"pl_fcast_err_0\": all_market_prices[round_num - 1] - float(forecast_dict['f0']) if ('f0' in forecast_dict and forecast_dict['f0']) else None,\n",
        "                \"pl_fcast_err_1\": all_market_prices[round_num + 1] - float(forecast_dict['f1']) if ('f1' in forecast_dict and forecast_dict['f1']) else None,\n",
        "                \"pl_fcast_err_2\": all_market_prices[round_num + 4] - float(forecast_dict['f2']) if ('f2' in forecast_dict and forecast_dict['f2']) else None,\n",
        "                \"pl_fcast_err_3\": all_market_prices[round_num + 9] - float(forecast_dict['f3']) if ('f3' in forecast_dict and forecast_dict['f3']) else None,\n",
        "                \"model\": model\n",
        "            }\n",
        "            row_df = pd.DataFrame([row]) \n",
        "            run_data = pd.concat([run_data, row_df], ignore_index=True)\n",
        "\n",
        "    return run_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_all_runs(runs, metadata):\n",
        "    def get_all_market_prices(run):\n",
        "        run_data_folder = \"run-\" + str(run) + \"/\"\n",
        "        bot_history_file = run_data_folder + \"bot-9-history.json\"\n",
        "\n",
        "        with open(bot_history_file) as f:\n",
        "            bot_history = json.load(f)\n",
        "\n",
        "        # Extract market data\n",
        "        market_prices = []\n",
        "        market_volumes = []\n",
        "        buy_back_price = bot_history[0]['market_state'][\"buy_back\"]\n",
        "\n",
        "        for entry in bot_history:\n",
        "            market_prices.append(entry['market_state'][\"market_price\"])\n",
        "            market_volumes.append(entry['market_state'][\"volume\"])\n",
        "        return market_prices\n",
        "    # Get all metadata for the runs\n",
        "    run_metadata = parse_metadata(metadata)\n",
        "    # Make master dataframe\n",
        "    df = pd.DataFrame(columns=columns)\n",
        "\n",
        "    for run in runs:\n",
        "        all_market_prices = get_all_market_prices(run)\n",
        "        run_df = extract_run(run, run_metadata[run], all_market_prices)\n",
        "        # add to master dataframe\n",
        "        df = pd.concat([df, run_df])\n",
        "\n",
        "    # Write to csv\n",
        "    df.to_csv(output_csv, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/bh/rfktsbfx39ggqr2wkkqc79b80000gn/T/ipykernel_26880/983041832.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  run_data = pd.concat([run_data, row_df], ignore_index=True)\n",
            "/var/folders/bh/rfktsbfx39ggqr2wkkqc79b80000gn/T/ipykernel_26880/643292292.py:27: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df = pd.concat([df, run_df])\n",
            "/var/folders/bh/rfktsbfx39ggqr2wkkqc79b80000gn/T/ipykernel_26880/983041832.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  run_data = pd.concat([run_data, row_df], ignore_index=True)\n",
            "/var/folders/bh/rfktsbfx39ggqr2wkkqc79b80000gn/T/ipykernel_26880/983041832.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  run_data = pd.concat([run_data, row_df], ignore_index=True)\n",
            "/var/folders/bh/rfktsbfx39ggqr2wkkqc79b80000gn/T/ipykernel_26880/983041832.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  run_data = pd.concat([run_data, row_df], ignore_index=True)\n",
            "/var/folders/bh/rfktsbfx39ggqr2wkkqc79b80000gn/T/ipykernel_26880/983041832.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  run_data = pd.concat([run_data, row_df], ignore_index=True)\n",
            "/var/folders/bh/rfktsbfx39ggqr2wkkqc79b80000gn/T/ipykernel_26880/983041832.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  run_data = pd.concat([run_data, row_df], ignore_index=True)\n",
            "/var/folders/bh/rfktsbfx39ggqr2wkkqc79b80000gn/T/ipykernel_26880/983041832.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  run_data = pd.concat([run_data, row_df], ignore_index=True)\n",
            "/var/folders/bh/rfktsbfx39ggqr2wkkqc79b80000gn/T/ipykernel_26880/983041832.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  run_data = pd.concat([run_data, row_df], ignore_index=True)\n",
            "/var/folders/bh/rfktsbfx39ggqr2wkkqc79b80000gn/T/ipykernel_26880/983041832.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  run_data = pd.concat([run_data, row_df], ignore_index=True)\n",
            "/var/folders/bh/rfktsbfx39ggqr2wkkqc79b80000gn/T/ipykernel_26880/983041832.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  run_data = pd.concat([run_data, row_df], ignore_index=True)\n",
            "/var/folders/bh/rfktsbfx39ggqr2wkkqc79b80000gn/T/ipykernel_26880/983041832.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  run_data = pd.concat([run_data, row_df], ignore_index=True)\n",
            "/var/folders/bh/rfktsbfx39ggqr2wkkqc79b80000gn/T/ipykernel_26880/983041832.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  run_data = pd.concat([run_data, row_df], ignore_index=True)\n",
            "/var/folders/bh/rfktsbfx39ggqr2wkkqc79b80000gn/T/ipykernel_26880/983041832.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  run_data = pd.concat([run_data, row_df], ignore_index=True)\n",
            "/var/folders/bh/rfktsbfx39ggqr2wkkqc79b80000gn/T/ipykernel_26880/983041832.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  run_data = pd.concat([run_data, row_df], ignore_index=True)\n",
            "/var/folders/bh/rfktsbfx39ggqr2wkkqc79b80000gn/T/ipykernel_26880/983041832.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  run_data = pd.concat([run_data, row_df], ignore_index=True)\n",
            "/var/folders/bh/rfktsbfx39ggqr2wkkqc79b80000gn/T/ipykernel_26880/983041832.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  run_data = pd.concat([run_data, row_df], ignore_index=True)\n",
            "/var/folders/bh/rfktsbfx39ggqr2wkkqc79b80000gn/T/ipykernel_26880/983041832.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  run_data = pd.concat([run_data, row_df], ignore_index=True)\n",
            "/var/folders/bh/rfktsbfx39ggqr2wkkqc79b80000gn/T/ipykernel_26880/983041832.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  run_data = pd.concat([run_data, row_df], ignore_index=True)\n",
            "/var/folders/bh/rfktsbfx39ggqr2wkkqc79b80000gn/T/ipykernel_26880/983041832.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  run_data = pd.concat([run_data, row_df], ignore_index=True)\n",
            "/var/folders/bh/rfktsbfx39ggqr2wkkqc79b80000gn/T/ipykernel_26880/983041832.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  run_data = pd.concat([run_data, row_df], ignore_index=True)\n",
            "/var/folders/bh/rfktsbfx39ggqr2wkkqc79b80000gn/T/ipykernel_26880/983041832.py:46: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  run_data = pd.concat([run_data, row_df], ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "extract_all_runs(runs, metadata_file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
